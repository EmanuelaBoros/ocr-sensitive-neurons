{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d3e8316-6769-44e1-b522-cb4b35fc4541",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/jalammar/ecco/blob/main/notebooks/Ecco_CCA_Similarity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c05bfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install ecco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b573b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d82cd6e523414790abefa87bfc56226f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/967 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d1a34458a824b1091294ae5eb4ccf16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fff22059e70f48589754dbd8d07a45c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "577a68be7b5f4a45802b5a8c1492c5a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('mistralai/Mistral-7B-v0.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4aca4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''Now I ask you: what can be expected of man since he is a being endowed with strange qualities? Shower upon him every earthly blessing, drown him in a sea of happiness, so that nothing but bubbles of bliss can be seen on the surface; give him economic prosperity, such that he should have nothing else to do but sleep, eat cakes and busy himself with the continuation of his species, and even then out of sheer ingratitude, sheer spite, man would play you some nasty trick. He would even risk his cakes and would deliberately desire the most fatal rubbish, the most uneconomical absurdity, simply to introduce into all this positive good sense his fatal fantastic element. It is just his fantastic dreams, his vulgar folly that he will desire to retain, simply in order to prove to himself--as though that were so necessary-- that men still are men and not the keys of a piano, which the laws of nature threaten to control so completely that soon one will be able to desire nothing but by the calendar. And that is not all: even if man really were nothing but a piano-key, even if this were proved to him by natural science and mathematics, even then he would not become reasonable, but would purposely do something perverse out of simple ingratitude, simply to gain his point. And if he does not find means he will contrive destruction and chaos, will contrive sufferings of all sorts, only to gain his point! He will launch a curse upon the world, and as only man can curse (it is his privilege, the primary distinction between him and other animals), may be by his curse alone he will attain his object--that is, convince himself that he is a man and not a piano-key!\n",
    "'''\n",
    "\n",
    "encoded = tokenizer([text], return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0fe6cef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁Now',\n",
       " '▁I',\n",
       " '▁ask',\n",
       " '▁you',\n",
       " ':',\n",
       " '▁what',\n",
       " '▁can',\n",
       " '▁be',\n",
       " '▁expected',\n",
       " '▁of',\n",
       " '▁man',\n",
       " '▁since',\n",
       " '▁he',\n",
       " '▁is',\n",
       " '▁a',\n",
       " '▁being',\n",
       " '▁end',\n",
       " 'owed',\n",
       " '▁with',\n",
       " '▁strange',\n",
       " '▁qualities',\n",
       " '?',\n",
       " '▁Sh',\n",
       " 'ower',\n",
       " '▁upon',\n",
       " '▁him',\n",
       " '▁every',\n",
       " '▁earth',\n",
       " 'ly',\n",
       " '▁blessing',\n",
       " ',',\n",
       " '▁d',\n",
       " 'rown',\n",
       " '▁him',\n",
       " '▁in',\n",
       " '▁a',\n",
       " '▁sea',\n",
       " '▁of',\n",
       " '▁happiness',\n",
       " ',',\n",
       " '▁so',\n",
       " '▁that',\n",
       " '▁nothing',\n",
       " '▁but',\n",
       " '▁bub',\n",
       " 'bles',\n",
       " '▁of',\n",
       " '▁bl',\n",
       " 'iss',\n",
       " '▁can',\n",
       " '▁be',\n",
       " '▁seen',\n",
       " '▁on',\n",
       " '▁the',\n",
       " '▁surface',\n",
       " ';',\n",
       " '▁give',\n",
       " '▁him',\n",
       " '▁economic',\n",
       " '▁prosper',\n",
       " 'ity',\n",
       " ',',\n",
       " '▁such',\n",
       " '▁that',\n",
       " '▁he',\n",
       " '▁should',\n",
       " '▁have',\n",
       " '▁nothing',\n",
       " '▁else',\n",
       " '▁to',\n",
       " '▁do',\n",
       " '▁but',\n",
       " '▁sleep',\n",
       " ',',\n",
       " '▁eat',\n",
       " '▁c',\n",
       " 'akes',\n",
       " '▁and',\n",
       " '▁busy',\n",
       " '▁himself',\n",
       " '▁with',\n",
       " '▁the',\n",
       " '▁continu',\n",
       " 'ation',\n",
       " '▁of',\n",
       " '▁his',\n",
       " '▁species',\n",
       " ',',\n",
       " '▁and',\n",
       " '▁even',\n",
       " '▁then',\n",
       " '▁out',\n",
       " '▁of',\n",
       " '▁sheer',\n",
       " '▁ing',\n",
       " 'rat',\n",
       " 'itude',\n",
       " ',',\n",
       " '▁sheer',\n",
       " '▁spite',\n",
       " ',',\n",
       " '▁man',\n",
       " '▁would',\n",
       " '▁play',\n",
       " '▁you',\n",
       " '▁some',\n",
       " '▁nasty',\n",
       " '▁trick',\n",
       " '.',\n",
       " '▁He',\n",
       " '▁would',\n",
       " '▁even',\n",
       " '▁risk',\n",
       " '▁his',\n",
       " '▁c',\n",
       " 'akes',\n",
       " '▁and',\n",
       " '▁would',\n",
       " '▁deliberately',\n",
       " '▁desire',\n",
       " '▁the',\n",
       " '▁most',\n",
       " '▁fatal',\n",
       " '▁rub',\n",
       " 'b',\n",
       " 'ish',\n",
       " ',',\n",
       " '▁the',\n",
       " '▁most',\n",
       " '▁une',\n",
       " 'conom',\n",
       " 'ical',\n",
       " '▁absurd',\n",
       " 'ity',\n",
       " ',',\n",
       " '▁simply',\n",
       " '▁to',\n",
       " '▁introduce',\n",
       " '▁into',\n",
       " '▁all',\n",
       " '▁this',\n",
       " '▁positive',\n",
       " '▁good',\n",
       " '▁sense',\n",
       " '▁his',\n",
       " '▁fatal',\n",
       " '▁fantastic',\n",
       " '▁element',\n",
       " '.',\n",
       " '▁It',\n",
       " '▁is',\n",
       " '▁just',\n",
       " '▁his',\n",
       " '▁fantastic',\n",
       " '▁dreams',\n",
       " ',',\n",
       " '▁his',\n",
       " '▁vul',\n",
       " 'gar',\n",
       " '▁fol',\n",
       " 'ly',\n",
       " '▁that',\n",
       " '▁he',\n",
       " '▁will',\n",
       " '▁desire',\n",
       " '▁to',\n",
       " '▁retain',\n",
       " ',',\n",
       " '▁simply',\n",
       " '▁in',\n",
       " '▁order',\n",
       " '▁to',\n",
       " '▁prove',\n",
       " '▁to',\n",
       " '▁himself',\n",
       " '--',\n",
       " 'as',\n",
       " '▁though',\n",
       " '▁that',\n",
       " '▁were',\n",
       " '▁so',\n",
       " '▁necessary',\n",
       " '--',\n",
       " '▁that',\n",
       " '▁men',\n",
       " '▁still',\n",
       " '▁are',\n",
       " '▁men',\n",
       " '▁and',\n",
       " '▁not',\n",
       " '▁the',\n",
       " '▁keys',\n",
       " '▁of',\n",
       " '▁a',\n",
       " '▁piano',\n",
       " ',',\n",
       " '▁which',\n",
       " '▁the',\n",
       " '▁laws',\n",
       " '▁of',\n",
       " '▁nature',\n",
       " '▁threat',\n",
       " 'en',\n",
       " '▁to',\n",
       " '▁control',\n",
       " '▁so',\n",
       " '▁completely',\n",
       " '▁that',\n",
       " '▁soon',\n",
       " '▁one',\n",
       " '▁will',\n",
       " '▁be',\n",
       " '▁able',\n",
       " '▁to',\n",
       " '▁desire',\n",
       " '▁nothing',\n",
       " '▁but',\n",
       " '▁by',\n",
       " '▁the',\n",
       " '▁calendar',\n",
       " '.',\n",
       " '▁And',\n",
       " '▁that',\n",
       " '▁is',\n",
       " '▁not',\n",
       " '▁all',\n",
       " ':',\n",
       " '▁even',\n",
       " '▁if',\n",
       " '▁man',\n",
       " '▁really',\n",
       " '▁were',\n",
       " '▁nothing',\n",
       " '▁but',\n",
       " '▁a',\n",
       " '▁piano',\n",
       " '-',\n",
       " 'key',\n",
       " ',',\n",
       " '▁even',\n",
       " '▁if',\n",
       " '▁this',\n",
       " '▁were',\n",
       " '▁proved',\n",
       " '▁to',\n",
       " '▁him',\n",
       " '▁by',\n",
       " '▁natural',\n",
       " '▁science',\n",
       " '▁and',\n",
       " '▁mathemat',\n",
       " 'ics',\n",
       " ',',\n",
       " '▁even',\n",
       " '▁then',\n",
       " '▁he',\n",
       " '▁would',\n",
       " '▁not',\n",
       " '▁become',\n",
       " '▁reasonable',\n",
       " ',',\n",
       " '▁but',\n",
       " '▁would',\n",
       " '▁pur',\n",
       " 'pos',\n",
       " 'ely',\n",
       " '▁do',\n",
       " '▁something',\n",
       " '▁per',\n",
       " 'verse',\n",
       " '▁out',\n",
       " '▁of',\n",
       " '▁simple',\n",
       " '▁ing',\n",
       " 'rat',\n",
       " 'itude',\n",
       " ',',\n",
       " '▁simply',\n",
       " '▁to',\n",
       " '▁gain',\n",
       " '▁his',\n",
       " '▁point',\n",
       " '.',\n",
       " '▁And',\n",
       " '▁if',\n",
       " '▁he',\n",
       " '▁does',\n",
       " '▁not',\n",
       " '▁find',\n",
       " '▁means',\n",
       " '▁he',\n",
       " '▁will',\n",
       " '▁cont',\n",
       " 'rive',\n",
       " '▁destruction',\n",
       " '▁and',\n",
       " '▁chaos',\n",
       " ',',\n",
       " '▁will',\n",
       " '▁cont',\n",
       " 'rive',\n",
       " '▁suffer',\n",
       " 'ings',\n",
       " '▁of',\n",
       " '▁all',\n",
       " '▁sorts',\n",
       " ',',\n",
       " '▁only',\n",
       " '▁to',\n",
       " '▁gain',\n",
       " '▁his',\n",
       " '▁point',\n",
       " '!',\n",
       " '▁He',\n",
       " '▁will',\n",
       " '▁launch',\n",
       " '▁a',\n",
       " '▁curse',\n",
       " '▁upon',\n",
       " '▁the',\n",
       " '▁world',\n",
       " ',',\n",
       " '▁and',\n",
       " '▁as',\n",
       " '▁only',\n",
       " '▁man',\n",
       " '▁can',\n",
       " '▁curse',\n",
       " '▁(',\n",
       " 'it',\n",
       " '▁is',\n",
       " '▁his',\n",
       " '▁privilege',\n",
       " ',',\n",
       " '▁the',\n",
       " '▁primary',\n",
       " '▁distinction',\n",
       " '▁between',\n",
       " '▁him',\n",
       " '▁and',\n",
       " '▁other',\n",
       " '▁animals',\n",
       " '),',\n",
       " '▁may',\n",
       " '▁be',\n",
       " '▁by',\n",
       " '▁his',\n",
       " '▁curse',\n",
       " '▁alone',\n",
       " '▁he',\n",
       " '▁will',\n",
       " '▁att',\n",
       " 'ain',\n",
       " '▁his',\n",
       " '▁object',\n",
       " '--',\n",
       " 'that',\n",
       " '▁is',\n",
       " ',',\n",
       " '▁convince',\n",
       " '▁himself',\n",
       " '▁that',\n",
       " '▁he',\n",
       " '▁is',\n",
       " '▁a',\n",
       " '▁man',\n",
       " '▁and',\n",
       " '▁not',\n",
       " '▁a',\n",
       " '▁piano',\n",
       " '-',\n",
       " 'key',\n",
       " '!',\n",
       " '<0x0A>']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str = \"This is a tokenization example\"\n",
    "tokenized = tokenizer.tokenize(text) \n",
    "\n",
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c35009a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>\n",
      "Now\n",
      "I\n",
      "ask\n",
      "you\n",
      ":\n",
      "what\n",
      "can\n",
      "be\n",
      "expected\n",
      "of\n",
      "man\n",
      "since\n",
      "he\n",
      "is\n",
      "a\n",
      "being\n",
      "end\n",
      "owed\n",
      "with\n",
      "strange\n",
      "qualities\n",
      "?\n",
      "Sh\n",
      "ower\n",
      "upon\n",
      "him\n",
      "every\n",
      "earth\n",
      "ly\n",
      "blessing\n",
      ",\n",
      "d\n",
      "rown\n",
      "him\n",
      "in\n",
      "a\n",
      "sea\n",
      "of\n",
      "happiness\n",
      ",\n",
      "so\n",
      "that\n",
      "nothing\n",
      "but\n",
      "bub\n",
      "bles\n",
      "of\n",
      "bl\n",
      "iss\n",
      "can\n",
      "be\n",
      "seen\n",
      "on\n",
      "the\n",
      "surface\n",
      ";\n",
      "give\n",
      "him\n",
      "economic\n",
      "prosper\n",
      "ity\n",
      ",\n",
      "such\n",
      "that\n",
      "he\n",
      "should\n",
      "have\n",
      "nothing\n",
      "else\n",
      "to\n",
      "do\n",
      "but\n",
      "sleep\n",
      ",\n",
      "eat\n",
      "c\n",
      "akes\n",
      "and\n",
      "busy\n",
      "himself\n",
      "with\n",
      "the\n",
      "continu\n",
      "ation\n",
      "of\n",
      "his\n",
      "species\n",
      ",\n",
      "and\n",
      "even\n",
      "then\n",
      "out\n",
      "of\n",
      "sheer\n",
      "ing\n",
      "rat\n",
      "itude\n",
      ",\n",
      "sheer\n",
      "spite\n",
      ",\n",
      "man\n",
      "would\n",
      "play\n",
      "you\n",
      "some\n",
      "nasty\n",
      "trick\n",
      ".\n",
      "He\n",
      "would\n",
      "even\n",
      "risk\n",
      "his\n",
      "c\n",
      "akes\n",
      "and\n",
      "would\n",
      "deliberately\n",
      "desire\n",
      "the\n",
      "most\n",
      "fatal\n",
      "rub\n",
      "b\n",
      "ish\n",
      ",\n",
      "the\n",
      "most\n",
      "une\n",
      "conom\n",
      "ical\n",
      "absurd\n",
      "ity\n",
      ",\n",
      "simply\n",
      "to\n",
      "introduce\n",
      "into\n",
      "all\n",
      "this\n",
      "positive\n",
      "good\n",
      "sense\n",
      "his\n",
      "fatal\n",
      "fantastic\n",
      "element\n",
      ".\n",
      "It\n",
      "is\n",
      "just\n",
      "his\n",
      "fantastic\n",
      "dreams\n",
      ",\n",
      "his\n",
      "vul\n",
      "gar\n",
      "fol\n",
      "ly\n",
      "that\n",
      "he\n",
      "will\n",
      "desire\n",
      "to\n",
      "retain\n",
      ",\n",
      "simply\n",
      "in\n",
      "order\n",
      "to\n",
      "prove\n",
      "to\n",
      "himself\n",
      "--\n",
      "as\n",
      "though\n",
      "that\n",
      "were\n",
      "so\n",
      "necessary\n",
      "--\n",
      "that\n",
      "men\n",
      "still\n",
      "are\n",
      "men\n",
      "and\n",
      "not\n",
      "the\n",
      "keys\n",
      "of\n",
      "a\n",
      "piano\n",
      ",\n",
      "which\n",
      "the\n",
      "laws\n",
      "of\n",
      "nature\n",
      "threat\n",
      "en\n",
      "to\n",
      "control\n",
      "so\n",
      "completely\n",
      "that\n",
      "soon\n",
      "one\n",
      "will\n",
      "be\n",
      "able\n",
      "to\n",
      "desire\n",
      "nothing\n",
      "but\n",
      "by\n",
      "the\n",
      "calendar\n",
      ".\n",
      "And\n",
      "that\n",
      "is\n",
      "not\n",
      "all\n",
      ":\n",
      "even\n",
      "if\n",
      "man\n",
      "really\n",
      "were\n",
      "nothing\n",
      "but\n",
      "a\n",
      "piano\n",
      "-\n",
      "key\n",
      ",\n",
      "even\n",
      "if\n",
      "this\n",
      "were\n",
      "proved\n",
      "to\n",
      "him\n",
      "by\n",
      "natural\n",
      "science\n",
      "and\n",
      "mathemat\n",
      "ics\n",
      ",\n",
      "even\n",
      "then\n",
      "he\n",
      "would\n",
      "not\n",
      "become\n",
      "reasonable\n",
      ",\n",
      "but\n",
      "would\n",
      "pur\n",
      "pos\n",
      "ely\n",
      "do\n",
      "something\n",
      "per\n",
      "verse\n",
      "out\n",
      "of\n",
      "simple\n",
      "ing\n",
      "rat\n",
      "itude\n",
      ",\n",
      "simply\n",
      "to\n",
      "gain\n",
      "his\n",
      "point\n",
      ".\n",
      "And\n",
      "if\n",
      "he\n",
      "does\n",
      "not\n",
      "find\n",
      "means\n",
      "he\n",
      "will\n",
      "cont\n",
      "rive\n",
      "destruction\n",
      "and\n",
      "chaos\n",
      ",\n",
      "will\n",
      "cont\n",
      "rive\n",
      "suffer\n",
      "ings\n",
      "of\n",
      "all\n",
      "sorts\n",
      ",\n",
      "only\n",
      "to\n",
      "gain\n",
      "his\n",
      "point\n",
      "!\n",
      "He\n",
      "will\n",
      "launch\n",
      "a\n",
      "curse\n",
      "upon\n",
      "the\n",
      "world\n",
      ",\n",
      "and\n",
      "as\n",
      "only\n",
      "man\n",
      "can\n",
      "curse\n",
      "(\n",
      "it\n",
      "is\n",
      "his\n",
      "privilege\n",
      ",\n",
      "the\n",
      "primary\n",
      "distinction\n",
      "between\n",
      "him\n",
      "and\n",
      "other\n",
      "animals\n",
      "),\n",
      "may\n",
      "be\n",
      "by\n",
      "his\n",
      "curse\n",
      "alone\n",
      "he\n",
      "will\n",
      "att\n",
      "ain\n",
      "his\n",
      "object\n",
      "--\n",
      "that\n",
      "is\n",
      ",\n",
      "convince\n",
      "himself\n",
      "that\n",
      "he\n",
      "is\n",
      "a\n",
      "man\n",
      "and\n",
      "not\n",
      "a\n",
      "piano\n",
      "-\n",
      "key\n",
      "!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in encoded['input_ids'][0]: print(tokenizer.decode(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d37c83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55290353-1c0f-4778-abd8-bb4c09969e1a",
   "metadata": {},
   "source": [
    "Load Ecco and BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "228061f6-2cfc-47ea-9357-6789c81745d1",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bb9e42851af408d97f9464276880e5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e42827ff61143c89fc790c42920bb54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00d63acd8600419aba38631554efad4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/eboros/.conda/envs/impresso_annotation_updated/lib/python3.11/site-packages/huggingface_hub/file_download.py:1003: UserWarning: Not enough free disk space to download the file. The expected file size is: 9942.98 MB. The target location /home/eboros/.cache/huggingface/hub only has 6372.20 MB free disk space.\n",
      "  warnings.warn(\n",
      "/scratch/eboros/.conda/envs/impresso_annotation_updated/lib/python3.11/site-packages/huggingface_hub/file_download.py:1003: UserWarning: Not enough free disk space to download the file. The expected file size is: 9942.98 MB. The target location /home/eboros/.cache/huggingface/hub/models--mistralai--Mistral-7B-v0.1/blobs only has 6372.20 MB free disk space.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fbb7746cc494868baf9665395136494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mecco\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m lm \u001b[38;5;241m=\u001b[39m ecco\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmistralai/Mistral-7B-v0.1\u001b[39m\u001b[38;5;124m'\u001b[39m, gpu\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/scratch/eboros/projects/ecco/src/ecco/__init__.py:83\u001b[0m, in \u001b[0;36mfrom_pretrained\u001b[0;34m(hf_model_id, model_config, activations, attention, hidden_states, activations_layer_nums, verbose, gpu)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     81\u001b[0m     model_cls \u001b[38;5;241m=\u001b[39m AutoModel\n\u001b[0;32m---> 83\u001b[0m model \u001b[38;5;241m=\u001b[39m model_cls\u001b[38;5;241m.\u001b[39mfrom_pretrained(hf_model_id, output_hidden_states\u001b[38;5;241m=\u001b[39mhidden_states, output_attentions\u001b[38;5;241m=\u001b[39mattention)\n\u001b[1;32m     85\u001b[0m lm_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m'\u001b[39m: hf_model_id,\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m'\u001b[39m: config,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m'\u001b[39m: verbose,\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m'\u001b[39m: gpu}\n\u001b[1;32m     93\u001b[0m lm \u001b[38;5;241m=\u001b[39m LM(model, tokenizer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlm_kwargs)\n",
      "File \u001b[0;32m/scratch/eboros/.conda/envs/impresso_annotation_updated/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:563\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    562\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    564\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    565\u001b[0m     )\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    567\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m )\n",
      "File \u001b[0;32m/scratch/eboros/.conda/envs/impresso_annotation_updated/lib/python3.11/site-packages/transformers/modeling_utils.py:3436\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3433\u001b[0m \u001b[38;5;66;03m# We'll need to download and cache each checkpoint shard if the checkpoint is sharded.\u001b[39;00m\n\u001b[1;32m   3434\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_sharded:\n\u001b[1;32m   3435\u001b[0m     \u001b[38;5;66;03m# rsolved_archive_file becomes a list of files that point to the different checkpoint shards in this case.\u001b[39;00m\n\u001b[0;32m-> 3436\u001b[0m     resolved_archive_file, sharded_metadata \u001b[38;5;241m=\u001b[39m get_checkpoint_shard_files(\n\u001b[1;32m   3437\u001b[0m         pretrained_model_name_or_path,\n\u001b[1;32m   3438\u001b[0m         resolved_archive_file,\n\u001b[1;32m   3439\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[1;32m   3440\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[1;32m   3441\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m   3442\u001b[0m         resume_download\u001b[38;5;241m=\u001b[39mresume_download,\n\u001b[1;32m   3443\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m   3444\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m   3445\u001b[0m         user_agent\u001b[38;5;241m=\u001b[39muser_agent,\n\u001b[1;32m   3446\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m   3447\u001b[0m         subfolder\u001b[38;5;241m=\u001b[39msubfolder,\n\u001b[1;32m   3448\u001b[0m         _commit_hash\u001b[38;5;241m=\u001b[39mcommit_hash,\n\u001b[1;32m   3449\u001b[0m     )\n\u001b[1;32m   3451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3452\u001b[0m     is_safetensors_available()\n\u001b[1;32m   3453\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resolved_archive_file, \u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m   3454\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m resolved_archive_file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.safetensors\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3455\u001b[0m ):\n\u001b[1;32m   3456\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m safe_open(resolved_archive_file, framework\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m/scratch/eboros/.conda/envs/impresso_annotation_updated/lib/python3.11/site-packages/transformers/utils/hub.py:1038\u001b[0m, in \u001b[0;36mget_checkpoint_shard_files\u001b[0;34m(pretrained_model_name_or_path, index_filename, cache_dir, force_download, proxies, resume_download, local_files_only, token, user_agent, revision, subfolder, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m shard_filename \u001b[38;5;129;01min\u001b[39;00m tqdm(shard_filenames, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading shards\u001b[39m\u001b[38;5;124m\"\u001b[39m, disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m show_progress_bar):\n\u001b[1;32m   1036\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1037\u001b[0m         \u001b[38;5;66;03m# Load from URL\u001b[39;00m\n\u001b[0;32m-> 1038\u001b[0m         cached_filename \u001b[38;5;241m=\u001b[39m cached_file(\n\u001b[1;32m   1039\u001b[0m             pretrained_model_name_or_path,\n\u001b[1;32m   1040\u001b[0m             shard_filename,\n\u001b[1;32m   1041\u001b[0m             cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[1;32m   1042\u001b[0m             force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[1;32m   1043\u001b[0m             proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m   1044\u001b[0m             resume_download\u001b[38;5;241m=\u001b[39mresume_download,\n\u001b[1;32m   1045\u001b[0m             local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m   1046\u001b[0m             token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m   1047\u001b[0m             user_agent\u001b[38;5;241m=\u001b[39muser_agent,\n\u001b[1;32m   1048\u001b[0m             revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m   1049\u001b[0m             subfolder\u001b[38;5;241m=\u001b[39msubfolder,\n\u001b[1;32m   1050\u001b[0m             _commit_hash\u001b[38;5;241m=\u001b[39m_commit_hash,\n\u001b[1;32m   1051\u001b[0m         )\n\u001b[1;32m   1052\u001b[0m     \u001b[38;5;66;03m# We have already dealt with RepositoryNotFoundError and RevisionNotFoundError when getting the index, so\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m     \u001b[38;5;66;03m# we don't have to catch them here.\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError:\n",
      "File \u001b[0;32m/scratch/eboros/.conda/envs/impresso_annotation_updated/lib/python3.11/site-packages/transformers/utils/hub.py:398\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    395\u001b[0m user_agent \u001b[38;5;241m=\u001b[39m http_user_agent(user_agent)\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 398\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m hf_hub_download(\n\u001b[1;32m    399\u001b[0m         path_or_repo_id,\n\u001b[1;32m    400\u001b[0m         filename,\n\u001b[1;32m    401\u001b[0m         subfolder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(subfolder) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m subfolder,\n\u001b[1;32m    402\u001b[0m         repo_type\u001b[38;5;241m=\u001b[39mrepo_type,\n\u001b[1;32m    403\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m    404\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[1;32m    405\u001b[0m         user_agent\u001b[38;5;241m=\u001b[39muser_agent,\n\u001b[1;32m    406\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[1;32m    407\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m    408\u001b[0m         resume_download\u001b[38;5;241m=\u001b[39mresume_download,\n\u001b[1;32m    409\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m    410\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m    411\u001b[0m     )\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    413\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m _get_cache_file_to_return(path_or_repo_id, full_filename, cache_dir, revision)\n",
      "File \u001b[0;32m/scratch/eboros/.conda/envs/impresso_annotation_updated/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:119\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    117\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/scratch/eboros/.conda/envs/impresso_annotation_updated/lib/python3.11/site-packages/huggingface_hub/file_download.py:1492\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, headers, legacy_cache_layout, endpoint)\u001b[0m\n\u001b[1;32m   1489\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m local_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1490\u001b[0m             _check_disk_space(expected_size, local_dir)\n\u001b[0;32m-> 1492\u001b[0m     http_get(\n\u001b[1;32m   1493\u001b[0m         url_to_download,\n\u001b[1;32m   1494\u001b[0m         temp_file,\n\u001b[1;32m   1495\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m   1496\u001b[0m         resume_size\u001b[38;5;241m=\u001b[39mresume_size,\n\u001b[1;32m   1497\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m   1498\u001b[0m         expected_size\u001b[38;5;241m=\u001b[39mexpected_size,\n\u001b[1;32m   1499\u001b[0m         displayed_filename\u001b[38;5;241m=\u001b[39mfilename,\n\u001b[1;32m   1500\u001b[0m     )\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m local_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1503\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStoring \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in cache at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mblob_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/scratch/eboros/.conda/envs/impresso_annotation_updated/lib/python3.11/site-packages/huggingface_hub/file_download.py:538\u001b[0m, in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers, expected_size, displayed_filename, _nb_retries, _tqdm_bar)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunk:  \u001b[38;5;66;03m# filter out keep-alive new chunks\u001b[39;00m\n\u001b[1;32m    537\u001b[0m     progress\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mlen\u001b[39m(chunk))\n\u001b[0;32m--> 538\u001b[0m     temp_file\u001b[38;5;241m.\u001b[39mwrite(chunk)\n\u001b[1;32m    539\u001b[0m     new_resume_size \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk)\n\u001b[1;32m    540\u001b[0m     \u001b[38;5;66;03m# Some data has been downloaded from the server so we reset the number of retries.\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/eboros/.conda/envs/impresso_annotation_updated/lib/python3.11/tempfile.py:483\u001b[0m, in \u001b[0;36m_TemporaryFileWrapper.__getattr__.<locals>.func_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;129m@_functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunc_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "import ecco\n",
    "lm = ecco.from_pretrained('mistralai/Mistral-7B-v0.1', gpu=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d1f126-e938-42f6-8e8c-fb97f79a2b74",
   "metadata": {},
   "source": [
    "Let's give BERT a passage of text to proccess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1abd436-50bf-4722-b113-73eaa795020d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html lang=\"en\">\n",
       "<script src=\"https://requirejs.org/docs/release/2.3.6/minified/require.js\"></script>\n",
       "<script>\n",
       "    var ecco_url = 'https://storage.googleapis.com/ml-intro/ecco/'\n",
       "    //var ecco_url = 'http://localhost:8000/'\n",
       "\n",
       "    if (window.ecco === undefined) window.ecco = {}\n",
       "\n",
       "    // Setup the paths of the script we'll be using\n",
       "    requirejs.config({\n",
       "        urlArgs: \"bust=\" + (new Date()).getTime(),\n",
       "        nodeRequire: require,\n",
       "        paths: {\n",
       "            d3: \"https://d3js.org/d3.v6.min\", // This is only for use in setup.html and basic.html\n",
       "            \"d3-array\": \"https://d3js.org/d3-array.v2.min\",\n",
       "            jquery: \"https://code.jquery.com/jquery-3.5.1.min\",\n",
       "            ecco: ecco_url + 'js/0.0.6/ecco-bundle.min',\n",
       "            xregexp: 'https://cdnjs.cloudflare.com/ajax/libs/xregexp/3.2.0/xregexp-all.min'\n",
       "        }\n",
       "    });\n",
       "\n",
       "    // Add the css file\n",
       "    //requirejs(['d3'],\n",
       "    //    function (d3) {\n",
       "    //        d3.select('#css').attr('href', ecco_url + 'html/styles.css')\n",
       "    //    })\n",
       "\n",
       "    console.log('Ecco initialize!!')\n",
       "\n",
       "    // returns a 'basic' object. basic.init() selects the html div we'll be\n",
       "    // rendering the html into, adds styles.css to the document.\n",
       "    define('basic', ['d3'],\n",
       "        function (d3) {\n",
       "            return {\n",
       "                init: function (viz_id = null) {\n",
       "                    if (viz_id == null) {\n",
       "                        viz_id = \"viz_\" + Math.round(Math.random() * 10000000)\n",
       "                    }\n",
       "                    // Select the div rendered below, change its id\n",
       "                    const div = d3.select('#basic').attr('id', viz_id),\n",
       "                        div_parent = d3.select('#' + viz_id).node().parentNode\n",
       "\n",
       "                    // Link to CSS file\n",
       "                    d3.select(div_parent).insert('link')\n",
       "                        .attr('rel', 'stylesheet')\n",
       "                        .attr('type', 'text/css')\n",
       "                        .attr('href', ecco_url + 'html/0.0.2/styles.css')\n",
       "\n",
       "                    return viz_id\n",
       "                }\n",
       "            }\n",
       "        }, function (err) {\n",
       "            console.log(err);\n",
       "        }\n",
       "    )\n",
       "</script>\n",
       "\n",
       "<head>\n",
       "    <link id='css' rel=\"stylesheet\" type=\"text/css\">\n",
       "</head>\n",
       "<div id=\"basic\"></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "         requirejs(['basic', 'ecco'], function(basic, ecco){\n",
       "            const viz_id = basic.init()\n",
       "\n",
       "            ecco.renderOutputSequence({\n",
       "                parentDiv: viz_id,\n",
       "                data: {'tokens': [{'token': 'Now', 'token_id': 3844, 'type': 'input'}, {'token': 'ĠI', 'token_id': 314, 'type': 'input'}, {'token': 'Ġask', 'token_id': 1265, 'type': 'input'}, {'token': 'Ġyou', 'token_id': 345, 'type': 'input'}, {'token': ':', 'token_id': 25, 'type': 'input'}, {'token': 'Ġwhat', 'token_id': 644, 'type': 'input'}, {'token': 'Ġcan', 'token_id': 460, 'type': 'input'}, {'token': 'Ġbe', 'token_id': 307, 'type': 'input'}, {'token': 'Ġexpected', 'token_id': 2938, 'type': 'input'}, {'token': 'Ġof', 'token_id': 286, 'type': 'input'}, {'token': 'Ġman', 'token_id': 582, 'type': 'input'}, {'token': 'Ġsince', 'token_id': 1201, 'type': 'input'}, {'token': 'Ġhe', 'token_id': 339, 'type': 'input'}, {'token': 'Ġis', 'token_id': 318, 'type': 'input'}, {'token': 'Ġa', 'token_id': 257, 'type': 'input'}, {'token': 'Ġbeing', 'token_id': 852, 'type': 'input'}, {'token': 'Ġendowed', 'token_id': 44134, 'type': 'input'}, {'token': 'Ġwith', 'token_id': 351, 'type': 'input'}, {'token': 'Ġstrange', 'token_id': 6283, 'type': 'input'}, {'token': 'Ġqualities', 'token_id': 14482, 'type': 'input'}, {'token': '?', 'token_id': 30, 'type': 'input'}, {'token': 'ĠSh', 'token_id': 911, 'type': 'input'}, {'token': 'ower', 'token_id': 789, 'type': 'input'}, {'token': 'Ġupon', 'token_id': 2402, 'type': 'input'}, {'token': 'Ġhim', 'token_id': 683, 'type': 'input'}, {'token': 'Ġevery', 'token_id': 790, 'type': 'input'}, {'token': 'Ġearthly', 'token_id': 39892, 'type': 'input'}, {'token': 'Ġblessing', 'token_id': 20027, 'type': 'input'}, {'token': ',', 'token_id': 11, 'type': 'input'}, {'token': 'Ġdrown', 'token_id': 16398, 'type': 'input'}, {'token': 'Ġhim', 'token_id': 683, 'type': 'input'}, {'token': 'Ġin', 'token_id': 287, 'type': 'input'}, {'token': 'Ġa', 'token_id': 257, 'type': 'input'}, {'token': 'Ġsea', 'token_id': 5417, 'type': 'input'}, {'token': 'Ġof', 'token_id': 286, 'type': 'input'}, {'token': 'Ġhappiness', 'token_id': 12157, 'type': 'input'}, {'token': ',', 'token_id': 11, 'type': 'input'}, {'token': 'Ġso', 'token_id': 523, 'type': 'input'}, {'token': 'Ġthat', 'token_id': 326, 'type': 'input'}, {'token': 'Ġnothing', 'token_id': 2147, 'type': 'input'}, {'token': 'Ġbut', 'token_id': 475, 'type': 'input'}, {'token': 'Ġbubbles', 'token_id': 25037, 'type': 'input'}, {'token': 'Ġof', 'token_id': 286, 'type': 'input'}, {'token': 'Ġbliss', 'token_id': 30533, 'type': 'input'}, {'token': 'Ġcan', 'token_id': 460, 'type': 'input'}, {'token': 'Ġbe', 'token_id': 307, 'type': 'input'}, {'token': 'Ġseen', 'token_id': 1775, 'type': 'input'}, {'token': 'Ġon', 'token_id': 319, 'type': 'input'}, {'token': 'Ġthe', 'token_id': 262, 'type': 'input'}, {'token': 'Ġsurface', 'token_id': 4417, 'type': 'input'}, {'token': ';', 'token_id': 26, 'type': 'input'}, {'token': 'Ġgive', 'token_id': 1577, 'type': 'input'}, {'token': 'Ġhim', 'token_id': 683, 'type': 'input'}, {'token': 'Ġeconomic', 'token_id': 3034, 'type': 'input'}, {'token': 'Ġprosperity', 'token_id': 19519, 'type': 'input'}, {'token': ',', 'token_id': 11, 'type': 'input'}, {'token': 'Ġsuch', 'token_id': 884, 'type': 'input'}, {'token': 'Ġthat', 'token_id': 326, 'type': 'input'}, {'token': 'Ġhe', 'token_id': 339, 'type': 'input'}, {'token': 'Ġshould', 'token_id': 815, 'type': 'input'}, {'token': 'Ġhave', 'token_id': 423, 'type': 'input'}, {'token': 'Ġnothing', 'token_id': 2147, 'type': 'input'}, {'token': 'Ġelse', 'token_id': 2073, 'type': 'input'}, {'token': 'Ġto', 'token_id': 284, 'type': 'input'}, {'token': 'Ġdo', 'token_id': 466, 'type': 'input'}, {'token': 'Ġbut', 'token_id': 475, 'type': 'input'}, {'token': 'Ġsleep', 'token_id': 3993, 'type': 'input'}, {'token': ',', 'token_id': 11, 'type': 'input'}, {'token': 'Ġeat', 'token_id': 4483, 'type': 'input'}, {'token': 'Ġcakes', 'token_id': 30849, 'type': 'input'}, {'token': 'Ġand', 'token_id': 290, 'type': 'input'}, {'token': 'Ġbusy', 'token_id': 8179, 'type': 'input'}, {'token': 'Ġhimself', 'token_id': 2241, 'type': 'input'}, {'token': 'Ġwith', 'token_id': 351, 'type': 'input'}, {'token': 'Ġthe', 'token_id': 262, 'type': 'input'}, {'token': 'Ġcontinuation', 'token_id': 24659, 'type': 'input'}, {'token': 'Ġof', 'token_id': 286, 'type': 'input'}, {'token': 'Ġhis', 'token_id': 465, 'type': 'input'}, {'token': 'Ġspecies', 'token_id': 4693, 'type': 'input'}, {'token': ',', 'token_id': 11, 'type': 'input'}, {'token': 'Ġand', 'token_id': 290, 'type': 'input'}, {'token': 'Ġeven', 'token_id': 772, 'type': 'input'}, {'token': 'Ġthen', 'token_id': 788, 'type': 'input'}, {'token': 'Ġout', 'token_id': 503, 'type': 'input'}, {'token': 'Ġof', 'token_id': 286, 'type': 'input'}, {'token': 'Ġsheer', 'token_id': 15163, 'type': 'input'}, {'token': 'Ġing', 'token_id': 5347, 'type': 'input'}, {'token': 'rat', 'token_id': 10366, 'type': 'input'}, {'token': 'itude', 'token_id': 3984, 'type': 'input'}, {'token': ',', 'token_id': 11, 'type': 'input'}, {'token': 'Ġsheer', 'token_id': 15163, 'type': 'input'}, {'token': 'Ġspite', 'token_id': 15275, 'type': 'input'}, {'token': ',', 'token_id': 11, 'type': 'input'}, {'token': 'Ġman', 'token_id': 582, 'type': 'input'}, {'token': 'Ġwould', 'token_id': 561, 'type': 'input'}, {'token': 'Ġplay', 'token_id': 711, 'type': 'input'}, {'token': 'Ġyou', 'token_id': 345, 'type': 'input'}, {'token': 'Ġsome', 'token_id': 617, 'type': 'input'}, {'token': 'Ġnasty', 'token_id': 17166, 'type': 'input'}, {'token': 'Ġtrick', 'token_id': 6908, 'type': 'input'}, {'token': '.', 'token_id': 13, 'type': 'input'}, {'token': 'ĠHe', 'token_id': 679, 'type': 'input'}, {'token': 'Ġwould', 'token_id': 561, 'type': 'input'}, {'token': 'Ġeven', 'token_id': 772, 'type': 'input'}, {'token': 'Ġrisk', 'token_id': 2526, 'type': 'input'}, {'token': 'Ġhis', 'token_id': 465, 'type': 'input'}, {'token': 'Ġcakes', 'token_id': 30849, 'type': 'input'}, {'token': 'Ġand', 'token_id': 290, 'type': 'input'}, {'token': 'Ġwould', 'token_id': 561, 'type': 'input'}, {'token': 'Ġdeliberately', 'token_id': 14593, 'type': 'input'}, {'token': 'Ġdesire', 'token_id': 6227, 'type': 'input'}, {'token': 'Ġthe', 'token_id': 262, 'type': 'input'}, {'token': 'Ġmost', 'token_id': 749, 'type': 'input'}, {'token': 'Ġfatal', 'token_id': 10800, 'type': 'input'}, {'token': 'Ġrubbish', 'token_id': 35022, 'type': 'input'}, {'token': ',', 'token_id': 11, 'type': 'input'}, {'token': 'Ġthe', 'token_id': 262, 'type': 'input'}, {'token': 'Ġmost', 'token_id': 749, 'type': 'input'}, {'token': 'Ġun', 'token_id': 555, 'type': 'input'}, {'token': 'econom', 'token_id': 13926, 'type': 'input'}, {'token': 'ical', 'token_id': 605, 'type': 'input'}, {'token': 'Ġabsurdity', 'token_id': 41793, 'type': 'input'}, {'token': ',', 'token_id': 11, 'type': 'input'}, {'token': 'Ġsimply', 'token_id': 2391, 'type': 'input'}, {'token': 'Ġto', 'token_id': 284, 'type': 'input'}, {'token': 'Ġintroduce', 'token_id': 10400, 'type': 'input'}, {'token': 'Ġinto', 'token_id': 656, 'type': 'input'}, {'token': 'Ġall', 'token_id': 477, 'type': 'input'}, {'token': 'Ġthis', 'token_id': 428, 'type': 'input'}, {'token': 'Ġpositive', 'token_id': 3967, 'type': 'input'}, {'token': 'Ġgood', 'token_id': 922, 'type': 'input'}, {'token': 'Ġsense', 'token_id': 2565, 'type': 'input'}, {'token': 'Ġhis', 'token_id': 465, 'type': 'input'}, {'token': 'Ġfatal', 'token_id': 10800, 'type': 'input'}, {'token': 'Ġfantastic', 'token_id': 9623, 'type': 'input'}, {'token': 'Ġelement', 'token_id': 5002, 'type': 'input'}, {'token': '.', 'token_id': 13, 'type': 'input'}, {'token': 'ĠIt', 'token_id': 632, 'type': 'input'}, {'token': 'Ġis', 'token_id': 318, 'type': 'input'}, {'token': 'Ġjust', 'token_id': 655, 'type': 'input'}, {'token': 'Ġhis', 'token_id': 465, 'type': 'input'}, {'token': 'Ġfantastic', 'token_id': 9623, 'type': 'input'}, {'token': 'Ġdreams', 'token_id': 10625, 'type': 'input'}, {'token': ',', 'token_id': 11, 'type': 'input'}, {'token': 'Ġhis', 'token_id': 465, 'type': 'input'}, {'token': 'Ġvulgar', 'token_id': 31016, 'type': 'input'}, {'token': 'Ġfolly', 'token_id': 43411, 'type': 'input'}, {'token': 'Ġthat', 'token_id': 326, 'type': 'input'}, {'token': 'Ġhe', 'token_id': 339, 'type': 'input'}, {'token': 'Ġwill', 'token_id': 481, 'type': 'input'}, {'token': 'Ġdesire', 'token_id': 6227, 'type': 'input'}, {'token': 'Ġto', 'token_id': 284, 'type': 'input'}, {'token': 'Ġretain', 'token_id': 12377, 'type': 'input'}, {'token': ',', 'token_id': 11, 'type': 'input'}, {'token': 'Ġsimply', 'token_id': 2391, 'type': 'input'}, {'token': 'Ġin', 'token_id': 287, 'type': 'input'}, {'token': 'Ġorder', 'token_id': 1502, 'type': 'input'}, {'token': 'Ġto', 'token_id': 284, 'type': 'input'}, {'token': 'Ġprove', 'token_id': 5879, 'type': 'input'}, {'token': 'Ġto', 'token_id': 284, 'type': 'input'}, {'token': 'Ġhimself', 'token_id': 2241, 'type': 'input'}, {'token': '--', 'token_id': 438, 'type': 'input'}, {'token': 'as', 'token_id': 292, 'type': 'input'}, {'token': 'Ġthough', 'token_id': 996, 'type': 'input'}, {'token': 'Ġthat', 'token_id': 326, 'type': 'input'}, {'token': 'Ġwere', 'token_id': 547, 'type': 'input'}, {'token': 'Ġso', 'token_id': 523, 'type': 'input'}, {'token': 'Ġnecessary', 'token_id': 3306, 'type': 'input'}, {'token': '--', 'token_id': 438, 'type': 'input'}, {'token': 'Ġthat', 'token_id': 326, 'type': 'input'}, {'token': 'Ġmen', 'token_id': 1450, 'type': 'input'}, {'token': 'Ġstill', 'token_id': 991, 'type': 'input'}, {'token': 'Ġare', 'token_id': 389, 'type': 'input'}, {'token': 'Ġmen', 'token_id': 1450, 'type': 'input'}, {'token': 'Ġand', 'token_id': 290, 'type': 'input'}, {'token': 'Ġnot', 'token_id': 407, 'type': 'input'}, {'token': 'Ġthe', 'token_id': 262, 'type': 'input'}, {'token': 'Ġkeys', 'token_id': 8251, 'type': 'input'}, {'token': 'Ġof', 'token_id': 286, 'type': 'input'}, {'token': 'Ġa', 'token_id': 257, 'type': 'input'}, {'token': 'Ġpiano', 'token_id': 19132, 'type': 'input'}, {'token': ',', 'token_id': 11, 'type': 'input'}, {'token': 'Ġwhich', 'token_id': 543, 'type': 'input'}, {'token': 'Ġthe', 'token_id': 262, 'type': 'input'}, {'token': 'Ġlaws', 'token_id': 3657, 'type': 'input'}, {'token': 'Ġof', 'token_id': 286, 'type': 'input'}, {'token': 'Ġnature', 'token_id': 3450, 'type': 'input'}, {'token': 'Ġthreaten', 'token_id': 16180, 'type': 'input'}, {'token': 'Ġto', 'token_id': 284, 'type': 'input'}, {'token': 'Ġcontrol', 'token_id': 1630, 'type': 'input'}, {'token': 'Ġso', 'token_id': 523, 'type': 'input'}, {'token': 'Ġcompletely', 'token_id': 3190, 'type': 'input'}, {'token': 'Ġthat', 'token_id': 326, 'type': 'input'}, {'token': 'Ġsoon', 'token_id': 2582, 'type': 'input'}, {'token': 'Ġone', 'token_id': 530, 'type': 'input'}, {'token': 'Ġwill', 'token_id': 481, 'type': 'input'}, {'token': 'Ġbe', 'token_id': 307, 'type': 'input'}, {'token': 'Ġable', 'token_id': 1498, 'type': 'input'}, {'token': 'Ġto', 'token_id': 284, 'type': 'input'}, {'token': 'Ġdesire', 'token_id': 6227, 'type': 'input'}, {'token': 'Ġnothing', 'token_id': 2147, 'type': 'input'}, {'token': 'Ġbut', 'token_id': 475, 'type': 'input'}, {'token': 'Ġby', 'token_id': 416, 'type': 'input'}, {'token': 'Ġthe', 'token_id': 262, 'type': 'input'}, {'token': 'Ġcalendar', 'token_id': 11845, 'type': 'input'}, {'token': '.', 'token_id': 13, 'type': 'input'}, {'token': 'ĠAnd', 'token_id': 843, 'type': 'input'}, {'token': 'Ġthat', 'token_id': 326, 'type': 'input'}, {'token': 'Ġis', 'token_id': 318, 'type': 'input'}, {'token': 'Ġnot', 'token_id': 407, 'type': 'input'}, {'token': 'Ġall', 'token_id': 477, 'type': 'input'}, {'token': ':', 'token_id': 25, 'type': 'input'}, {'token': 'Ġeven', 'token_id': 772, 'type': 'input'}, {'token': 'Ġif', 'token_id': 611, 'type': 'input'}, {'token': 'Ġman', 'token_id': 582, 'type': 'input'}, {'token': 'Ġreally', 'token_id': 1107, 'type': 'input'}, {'token': 'Ġwere', 'token_id': 547, 'type': 'input'}, {'token': 'Ġnothing', 'token_id': 2147, 'type': 'input'}, {'token': 'Ġbut', 'token_id': 475, 'type': 'input'}, {'token': 'Ġa', 'token_id': 257, 'type': 'input'}, {'token': 'Ġpiano', 'token_id': 19132, 'type': 'input'}, {'token': '-', 'token_id': 12, 'type': 'input'}, {'token': 'key', 'token_id': 2539, 'type': 'input'}, {'token': ',', 'token_id': 11, 'type': 'input'}, {'token': 'Ġeven', 'token_id': 772, 'type': 'input'}, {'token': 'Ġif', 'token_id': 611, 'type': 'input'}, {'token': 'Ġthis', 'token_id': 428, 'type': 'input'}, {'token': 'Ġwere', 'token_id': 547, 'type': 'input'}, {'token': 'Ġproved', 'token_id': 8302, 'type': 'input'}, {'token': 'Ġto', 'token_id': 284, 'type': 'input'}, {'token': 'Ġhim', 'token_id': 683, 'type': 'input'}, {'token': 'Ġby', 'token_id': 416, 'type': 'input'}, {'token': 'Ġnatural', 'token_id': 3288, 'type': 'input'}, {'token': 'Ġscience', 'token_id': 3783, 'type': 'input'}, {'token': 'Ġand', 'token_id': 290, 'type': 'input'}, {'token': 'Ġmathematics', 'token_id': 19473, 'type': 'input'}, {'token': ',', 'token_id': 11, 'type': 'input'}, {'token': 'Ġeven', 'token_id': 772, 'type': 'input'}, {'token': 'Ġthen', 'token_id': 788, 'type': 'input'}, {'token': 'Ġhe', 'token_id': 339, 'type': 'input'}, {'token': 'Ġwould', 'token_id': 561, 'type': 'input'}, {'token': 'Ġnot', 'token_id': 407, 'type': 'input'}, {'token': 'Ġbecome', 'token_id': 1716, 'type': 'input'}, {'token': 'Ġreasonable', 'token_id': 6397, 'type': 'input'}, {'token': ',', 'token_id': 11, 'type': 'input'}, {'token': 'Ġbut', 'token_id': 475, 'type': 'input'}, {'token': 'Ġwould', 'token_id': 561, 'type': 'input'}, {'token': 'Ġpurposely', 'token_id': 39033, 'type': 'input'}, {'token': 'Ġdo', 'token_id': 466, 'type': 'input'}, {'token': 'Ġsomething', 'token_id': 1223, 'type': 'input'}, {'token': 'Ġperverse', 'token_id': 43060, 'type': 'input'}, {'token': 'Ġout', 'token_id': 503, 'type': 'input'}, {'token': 'Ġof', 'token_id': 286, 'type': 'input'}, {'token': 'Ġsimple', 'token_id': 2829, 'type': 'input'}, {'token': 'Ġing', 'token_id': 5347, 'type': 'input'}, {'token': 'rat', 'token_id': 10366, 'type': 'input'}, {'token': 'itude', 'token_id': 3984, 'type': 'input'}, {'token': ',', 'token_id': 11, 'type': 'input'}, {'token': 'Ġsimply', 'token_id': 2391, 'type': 'input'}, {'token': 'Ġto', 'token_id': 284, 'type': 'input'}, {'token': 'Ġgain', 'token_id': 4461, 'type': 'input'}, {'token': 'Ġhis', 'token_id': 465, 'type': 'input'}, {'token': 'Ġpoint', 'token_id': 966, 'type': 'input'}, {'token': '.', 'token_id': 13, 'type': 'input'}, {'token': 'ĠAnd', 'token_id': 843, 'type': 'input'}, {'token': 'Ġif', 'token_id': 611, 'type': 'input'}, {'token': 'Ġhe', 'token_id': 339, 'type': 'input'}, {'token': 'Ġdoes', 'token_id': 857, 'type': 'input'}, {'token': 'Ġnot', 'token_id': 407, 'type': 'input'}, {'token': 'Ġfind', 'token_id': 1064, 'type': 'input'}, {'token': 'Ġmeans', 'token_id': 1724, 'type': 'input'}, {'token': 'Ġhe', 'token_id': 339, 'type': 'input'}, {'token': 'Ġwill', 'token_id': 481, 'type': 'input'}, {'token': 'Ġcont', 'token_id': 542, 'type': 'input'}, {'token': 'rive', 'token_id': 11590, 'type': 'input'}, {'token': 'Ġdestruction', 'token_id': 8166, 'type': 'input'}, {'token': 'Ġand', 'token_id': 290, 'type': 'input'}, {'token': 'Ġchaos', 'token_id': 11918, 'type': 'input'}, {'token': ',', 'token_id': 11, 'type': 'input'}, {'token': 'Ġwill', 'token_id': 481, 'type': 'input'}, {'token': 'Ġcont', 'token_id': 542, 'type': 'input'}, {'token': 'rive', 'token_id': 11590, 'type': 'input'}, {'token': 'Ġsuffer', 'token_id': 8659, 'type': 'input'}, {'token': 'ings', 'token_id': 654, 'type': 'input'}, {'token': 'Ġof', 'token_id': 286, 'type': 'input'}, {'token': 'Ġall', 'token_id': 477, 'type': 'input'}, {'token': 'Ġsorts', 'token_id': 10524, 'type': 'input'}, {'token': ',', 'token_id': 11, 'type': 'input'}, {'token': 'Ġonly', 'token_id': 691, 'type': 'input'}, {'token': 'Ġto', 'token_id': 284, 'type': 'input'}, {'token': 'Ġgain', 'token_id': 4461, 'type': 'input'}, {'token': 'Ġhis', 'token_id': 465, 'type': 'input'}, {'token': 'Ġpoint', 'token_id': 966, 'type': 'input'}, {'token': '!', 'token_id': 0, 'type': 'input'}, {'token': 'ĠHe', 'token_id': 679, 'type': 'input'}, {'token': 'Ġwill', 'token_id': 481, 'type': 'input'}, {'token': 'Ġlaunch', 'token_id': 4219, 'type': 'input'}, {'token': 'Ġa', 'token_id': 257, 'type': 'input'}, {'token': 'Ġcurse', 'token_id': 17328, 'type': 'input'}, {'token': 'Ġupon', 'token_id': 2402, 'type': 'input'}, {'token': 'Ġthe', 'token_id': 262, 'type': 'input'}, {'token': 'Ġworld', 'token_id': 995, 'type': 'input'}, {'token': ',', 'token_id': 11, 'type': 'input'}, {'token': 'Ġand', 'token_id': 290, 'type': 'input'}, {'token': 'Ġas', 'token_id': 355, 'type': 'input'}, {'token': 'Ġonly', 'token_id': 691, 'type': 'input'}, {'token': 'Ġman', 'token_id': 582, 'type': 'input'}, {'token': 'Ġcan', 'token_id': 460, 'type': 'input'}, {'token': 'Ġcurse', 'token_id': 17328, 'type': 'input'}, {'token': 'Ġ(', 'token_id': 357, 'type': 'input'}, {'token': 'it', 'token_id': 270, 'type': 'input'}, {'token': 'Ġis', 'token_id': 318, 'type': 'input'}, {'token': 'Ġhis', 'token_id': 465, 'type': 'input'}, {'token': 'Ġprivilege', 'token_id': 11941, 'type': 'input'}, {'token': ',', 'token_id': 11, 'type': 'input'}, {'token': 'Ġthe', 'token_id': 262, 'type': 'input'}, {'token': 'Ġprimary', 'token_id': 4165, 'type': 'input'}, {'token': 'Ġdistinction', 'token_id': 12941, 'type': 'input'}, {'token': 'Ġbetween', 'token_id': 1022, 'type': 'input'}, {'token': 'Ġhim', 'token_id': 683, 'type': 'input'}, {'token': 'Ġand', 'token_id': 290, 'type': 'input'}, {'token': 'Ġother', 'token_id': 584, 'type': 'input'}, {'token': 'Ġanimals', 'token_id': 4695, 'type': 'input'}, {'token': '),', 'token_id': 828, 'type': 'input'}, {'token': 'Ġmay', 'token_id': 743, 'type': 'input'}, {'token': 'Ġbe', 'token_id': 307, 'type': 'input'}, {'token': 'Ġby', 'token_id': 416, 'type': 'input'}, {'token': 'Ġhis', 'token_id': 465, 'type': 'input'}, {'token': 'Ġcurse', 'token_id': 17328, 'type': 'input'}, {'token': 'Ġalone', 'token_id': 3436, 'type': 'input'}, {'token': 'Ġhe', 'token_id': 339, 'type': 'input'}, {'token': 'Ġwill', 'token_id': 481, 'type': 'input'}, {'token': 'Ġattain', 'token_id': 18188, 'type': 'input'}, {'token': 'Ġhis', 'token_id': 465, 'type': 'input'}, {'token': 'Ġobject', 'token_id': 2134, 'type': 'input'}, {'token': '--', 'token_id': 438, 'type': 'input'}, {'token': 'that', 'token_id': 5562, 'type': 'input'}, {'token': 'Ġis', 'token_id': 318, 'type': 'input'}, {'token': ',', 'token_id': 11, 'type': 'input'}, {'token': 'Ġconvince', 'token_id': 11508, 'type': 'input'}, {'token': 'Ġhimself', 'token_id': 2241, 'type': 'input'}, {'token': 'Ġthat', 'token_id': 326, 'type': 'input'}, {'token': 'Ġhe', 'token_id': 339, 'type': 'input'}, {'token': 'Ġis', 'token_id': 318, 'type': 'input'}, {'token': 'Ġa', 'token_id': 257, 'type': 'input'}, {'token': 'Ġman', 'token_id': 582, 'type': 'input'}, {'token': 'Ġand', 'token_id': 290, 'type': 'input'}, {'token': 'Ġnot', 'token_id': 407, 'type': 'input'}, {'token': 'Ġa', 'token_id': 257, 'type': 'input'}, {'token': 'Ġpiano', 'token_id': 19132, 'type': 'input'}, {'token': '-', 'token_id': 12, 'type': 'input'}, {'token': 'key', 'token_id': 2539, 'type': 'input'}, {'token': '!', 'token_id': 0, 'type': 'input'}, {'token': 'Ċ', 'token_id': 198, 'type': 'input'}]},\n",
       "                tokenization_config: {\"token_prefix\": \"\\u0120\", \"partial_token_prefix\": \"\"}\n",
       "            })\n",
       "         }, function (err) {\n",
       "            console.log(err);\n",
       "        })"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<OutputSeq>"
      ],
      "text/plain": [
       "<ecco.output.OutputSeq at 0x7fb89ac02310>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '''Now I ask you: what can be expected of man since he is a being endowed with strange qualities? Shower upon him every earthly blessing, drown him in a sea of happiness, so that nothing but bubbles of bliss can be seen on the surface; give him economic prosperity, such that he should have nothing else to do but sleep, eat cakes and busy himself with the continuation of his species, and even then out of sheer ingratitude, sheer spite, man would play you some nasty trick. He would even risk his cakes and would deliberately desire the most fatal rubbish, the most uneconomical absurdity, simply to introduce into all this positive good sense his fatal fantastic element. It is just his fantastic dreams, his vulgar folly that he will desire to retain, simply in order to prove to himself--as though that were so necessary-- that men still are men and not the keys of a piano, which the laws of nature threaten to control so completely that soon one will be able to desire nothing but by the calendar. And that is not all: even if man really were nothing but a piano-key, even if this were proved to him by natural science and mathematics, even then he would not become reasonable, but would purposely do something perverse out of simple ingratitude, simply to gain his point. And if he does not find means he will contrive destruction and chaos, will contrive sufferings of all sorts, only to gain his point! He will launch a curse upon the world, and as only man can curse (it is his privilege, the primary distinction between him and other animals), may be by his curse alone he will attain his object--that is, convince himself that he is a man and not a piano-key!\n",
    "'''\n",
    "\n",
    "inputs = lm.tokenizer([text], return_tensors=\"pt\")\n",
    "output = lm(inputs)\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470b6fa8-1f45-42e6-afa8-ba6fbe576bb4",
   "metadata": {},
   "source": [
    "the `output` variable now contains the result of BERT processing the passge of text. The property `output.decoder_hidden_states` contains the hidden states after each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c97a987-c239-4f51-8f39-f4f00dfa9464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((768, 363), (768, 363), 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states = output._get_encoder_hidden_states()\n",
    "embed = output.embedding_states.detach().numpy()[0,:,:].T\n",
    "hidden_state_layer = [layer.detach().numpy()[0,:,:].T for layer in hidden_states]\n",
    "embed.shape, hidden_state_layer[0].shape, len(hidden_state_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ee4085-a697-4753-98b8-f930b4abcad0",
   "metadata": {},
   "source": [
    "`embed` now contains the embeddings of the inputs. Its dimensions are (embed_dim, number of tokens). \n",
    "`hidden_state_layer` has the outputs of each of the model's 6 layers. The output of each layer is (embed_dim, number of tokens).\n",
    "\n",
    "This is how to calculate the cka similarity score between the embeddings layer and the output of the first layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fe8fa2b-39b7-4a04-bf4e-c62cffe3f2ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9042735255823328"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ecco import analysis\n",
    "analysis.cka(embed, hidden_state_layer[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831da973-63bc-4a53-8022-8017ee82af57",
   "metadata": {},
   "source": [
    "When we compare the embeddings with the output of the second layer, we see less similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d428f519-fb48-402d-8bea-962783fe36de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7774274463814453"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.cka(embed, hidden_state_layer[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823e071c-ccc2-458e-b792-8d451bd48e41",
   "metadata": {},
   "source": [
    "And so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8621e099-a768-4e17-86e6-6281c4fe4a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6922863613160068"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.cka(embed, hidden_state_layer[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2de6f2-fe10-4672-ae51-cfdfe2382be2",
   "metadata": {},
   "source": [
    "We can try with `cca`, `svcca` and `pwcca`. But we need to choose a subset of the neurons because these methods require more tokens than neurons (and advise 10x as many tokens as neurons to get a proper similarity score). \n",
    "\n",
    "Let's compare the similarities of the first 50 neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc3f50a6-eaa0-498e-896a-11d333d7fb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCA - Embed vs. layer 0: 0.8518187688700852\n",
      "CCA - Embed vs. layer 1: 0.7220358158064838\n"
     ]
    }
   ],
   "source": [
    "print(\"CCA - Embed vs. layer 0:\", analysis.cca(embed[:50,:], hidden_state_layer[0][:50,:]))\n",
    "print(\"CCA - Embed vs. layer 1:\", analysis.cca(embed[:50,:], hidden_state_layer[1][:50,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebb5d691-af03-4d0c-9282-c5338671df12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVCCA - Embed vs. layer 0: 0.7830642779004243\n",
      "SVCCA - Embed vs. layer 1: 0.6833412966387719\n"
     ]
    }
   ],
   "source": [
    "print(\"SVCCA - Embed vs. layer 0:\", analysis.svcca(embed[:50,:], hidden_state_layer[0][:50,:]))\n",
    "print(\"SVCCA - Embed vs. layer 1:\", analysis.svcca(embed[:50,:], hidden_state_layer[1][:50,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b3e47b3-e5a6-47ce-8964-29eb086e29ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PWCCA - Embed vs. layer 0: 0.8695735290407357\n",
      "PWCCA - Embed vs. layer 1: 0.7461958851582353\n"
     ]
    }
   ],
   "source": [
    "print(\"PWCCA - Embed vs. layer 0:\", analysis.pwcca(embed[:50,:], hidden_state_layer[0][:50,:]))\n",
    "print(\"PWCCA - Embed vs. layer 1:\", analysis.pwcca(embed[:50,:], hidden_state_layer[1][:50,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e4e49a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
